{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 04: Networks from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will learn to construct a network from a set of implicit relationships. The relationships that we will study are between accounts in Twitter, a micro-blogging service.\n",
    "\n",
    "We will create two networks: one directed and one undirected.\n",
    "\n",
    "* In the **directed mention network**, we will say that there is a link of weight *w* from account *x* to account *y*, if account *x* has re-tweeted (re-posted) or mentioned *w* times account *y*.\n",
    "\n",
    "* In the **undirected co-mention network**, we will say that there is a link of weight *w* between accounts *x* and *y*, if both accounts have been mentioned together in *w* tweets.\n",
    "\n",
    "The input material you will use is a file named `CovidLockdownCatalonia.json.gz` available in the data/ directory. This is a gzip-compressed file, which you can de-compress either from your python code (as detailed below) or using the `gunzip` command. This file contains about 35,500 messages (\"tweets\") posted between March 13th, 2020, and March 14th, 2020, containing a hashtag or keyword related to COVID-19, and posted by a user declaring a location in Catalonia. Each tweet is contained in a single line.\n",
    "\n",
    "*Advice: be carefull if you want to open `CovidLockdownCatalonia.json`, it lasts for a long time to load and can freeze your computer. It should be better to have a glance at `CovidLockdownCatalonia_sample-10-lines.json` instead, which contains only the first 10 lines (these lines have been formatted by introducing some carriage returs for ease insight).*\n",
    "\n",
    "The tweets are in a format known as [JSON](https://en.wikipedia.org/wiki/JSON#Example). Python's JSON library takes care of translating it into a dictionary.\n",
    "\n",
    "**How was this file obtained?** This file was obtained from the [CrisisNLP](https://crisisnlp.qcri.org/covid19). This is a website that provides COVID-19 collections of tweets, however, they only provide the identifier of the tweet, known as a tweet-id. To recover the entire tweet, a process commonly known as *re-hydration* was used, which involves querying an API from Twitter, giving the tweet-id, and obtaining the tweet. This can be done with a little bit of programming or using a software such as [twarc](https://github.com/DocNow/twarc#dehydrate).\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: <font color=\"blue\">Your name here</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">Your e-mail here</font>\n",
    "\n",
    "Date: <font color=\"blue\">The current date here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create the directed mention network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the **directed mention network**, which has a weighted edge (source, target, weight) if user *source* mentioned user *target* at least once; with *weight* indicating the number of mentions.\n",
    "\n",
    "Create two files: one containing all edges, and one containing all edges having *count* greater or equal than 2.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import gzip\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "# Input file\n",
    "COMPRESSED_INPUT_FILENAME = \"data/CovidLockdownCatalonia.json.gz\"\n",
    "\n",
    "# These are the output files, leave as-is\n",
    "OUTPUT_ALL_EDGES_FILENAME = \"delivery/CovidLockdownCatalonia.csv\"\n",
    "OUTPUT_FILTERED_EDGES_FILENAME = \"delivery/CovidLockdownCatalonia-min-weight-filtered.csv\"\n",
    "OUTPUT_CO_MENTIONS_FILENAME = \"delivery/CovidLockdownCatalonia-co-mentions.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Extract mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `extract_mentions(text)` function is used to extract mentions, so that if we give, for instance `RT @Jordi: check this post by @Xavier`, it returns the list `[\"Jordi\", \"Xavier\"]`.\n",
    "\n",
    "Note that you need an `import re` command together with the other imports. RE module provide utilities for using regular expressions, which will be used to extract user names form patterns beginning with @.\n",
    "\n",
    "You can now print all the people mentioned in a tweet by doing:\n",
    "\n",
    "```python\n",
    "mentions = extract_mentions(message)\n",
    "for mention in mentions:\n",
    "    print(\"%s mentioned %s\" % (author, mention))\n",
    "```\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def extract_mentions(text):\n",
    "    return re.findall(\"@([a-zA-Z0-9_]{5,20})\", text)\n",
    "\n",
    "print(extract_mentions(\"RT @Jordi: check this post by @Xavier\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Count mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need to uncompress this file (it is about 236 MB uncompressed, but only 31 MB compressed), but we can read it directly while it is compressed.\n",
    "\n",
    "```python\n",
    "with gzip.open(COMPRESSED_INPUT_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "    for line in input_file:\n",
    "        tweet = json.loads(line)\n",
    "        author = tweet[\"user\"][\"screen_name\"]\n",
    "        message = tweet[\"full_text\"]\n",
    "        print(\"%s: '%s'\" % (author, message))\n",
    "```\n",
    "\n",
    "To count how many times a mention happens, you will keep a dictionary:\n",
    "\n",
    "```python\n",
    "mentions_counter = {}\n",
    "```\n",
    "\n",
    "Each key in the dictionary will be a tuple `(author, mention)` where `author` is the username of the person who writes the message, and `mention` the username of someone who is mentioned in the message. To update the dictionary, use this code while you are reading the input file:\n",
    "\n",
    "```python\n",
    "for mention in mentions:\n",
    "    key = (author, mention)\n",
    "    if key in mentions_counter:\n",
    "        mentions_counter[key] += 1\n",
    "    else:\n",
    "        mentions_counter[key] = 1\n",
    "```\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to read the compressed input file and create the mentions_counter dictionary.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of times the account `joanmariapique` mentioned `catalangov`. It should be 9.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to print the number of times the account `joanmariapique` mentioned `catalangov`.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write a file with all the edges in this graph (Source, Target, Weight) as a tab-separated file.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "with io.open(OUTPUT_ALL_EDGES_FILENAME, \"w\") as output_file:\n",
    "    writer = csv.writer(output_file, delimiter='\\t', quotechar='\"', lineterminator='\\n')\n",
    "    writer.writerow([\"Source\", \"Target\", \"Weight\"])\n",
    "    for key in mentions_counter:\n",
    "        author = key[0]\n",
    "        mention = key[1]\n",
    "        weight = mentions_counter[key]\n",
    "        writer.writerow([author, mention, weight])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to create a file named `OUTPUT_FILTERED_EDGES_FILENAME` containing all (author, mention) pairs with a value greater or equal to 2.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize the directed mention network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the **filtered** edge file in Cytoscape, by importing its CSV file. You may have to set the delimiter to \"Tab\" in the advanced options, when importing.\n",
    "\n",
    "The file is large so if you want to see all details while zooming out you may have to set ``View > Always show Graphic Details``. Note this makes the program run slower.\n",
    "\n",
    "Style the network:\n",
    "\n",
    "* Run \"Tools > Analyze Network ...\" (as a directed graph)\n",
    "* Style nodes by setting their size proportional to their in-degree\n",
    "* Style edges by setting their width and color (darker=more) using the *weight* attribute.\n",
    "* Style edges by setting Target Arrow Shape to column *interaction*, Mapping Type to *Discrete Mapping*, and interacts with to *Arrow*\n",
    "\n",
    "*Tip*: to count nodes in Cytoscape, hold shift while clicking and select the nodes. In the lower-right corner you should see a count of nodes and edges.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Save the image as mentions.png and replace this cell with `![Mentions graph](mentions.png)` to display your graph.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with a brief commentary of what you see in this graph. What is the size of the largest connected component, both as a number of nodes and as a percentage of the nodes in the graph? What is the size of the second largest connected component?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the largest connected component, deleting the rest of the nodes (you can hold shift while drawing a rectangle, to select some nodes).\n",
    "\n",
    "Run the ClusterMaker2 plug-in to create a clustering (affinity propagation clustering) of this graph using the *weight* edge attribute. Color nodes according to their cluster, using a discrete mapping. Note that if you right-click on \"Mapping type\" when creating a discrete mapping, you can use an automatic mapping generator that you can fine-tune later.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Save the image as mentions-largest-cc.png and replace this cell with `![Mentions graph largest connected component](mentions-largest-cc.png)` to display your graph.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the Results Panel of the network analyzer. There is interesting information here, particularly the node degree distribution.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Save the plots of the in-degree distribution and the out-degree distribution replace this cell with `![Mentions in-degree distribution](mentions-in-degree-distribution.png)` and `![Mentions out-degree distribution](mentions-out-degree-distribution.png)` to display them.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell by a brief commentary, in your own words, of what you see in this graph. What type of graph is it? Which kinds of nodes are high-centrality nodes? Include any aspects that you find relevant from the results of the network analyzer (e.g., number of nodes, edges, connected components, characteristic path lengths, average degrees, etc.) and indicate why those aspects are relevant</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create the undirected co-mention network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **undirected co-mention network** connects two accounts if they are both mentioned in the same tweet. The weight of the edge is the number of tweets in which the accounts are co-mentioned.\n",
    "\n",
    "Suppose the mentions in a Tweet are in the array ``mentions``, then you can iterate through all pairs of co-mentioned like this:\n",
    "\n",
    "```python\n",
    "for mention1 in mentions:\n",
    "    for mention2 in mentions:\n",
    "        if mention1 < mention2:\n",
    "            key = (mention1, mention2)\n",
    "```\n",
    "\n",
    "Read the input file again to create a dictionary `co_mentions_counter` in which keys are tuples (user1, user2) in which user1 lexicographically precedes user2 (user1 < user2), and values are the number of times user1 and user2 have appeared together in a tweet.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to create the `co_mentions_counter`.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of times the accounts `agriculturacat` and `uniopagesos` have been mentioned together. It should be 8.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to print the number of times the accounts `agriculturacat` and `uniopagesos` have been mentioned together.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a file named `OUTPUT_CO_MENTIONS_FILENAME` containing co-mentions in tab-separated columns Source, Target, Weight.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code to create the co-mentions file.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Visualize the undirected co-mention network in Cytoscape\n",
    "\n",
    "Open the `OUTPUT_CO_MENTIONS_FILENAME` file in Cytoscape.\n",
    "\n",
    "Style the network so that line widths are larger for edges with large weights, and node sizes are larger for nodes with large degrees. Remember you need to run the network analyzer first.\n",
    "\n",
    "Use \"Layout > Prefuse Force Directed Layout > All Nodes > Weight\" to create a layout by edge weight.\n",
    "\n",
    "Run a clustering algorithm within Cytoscape to create a clustering of this graph using the *Weight* attribute as weight, and assign colors to the different clusters.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Save the image as co-mentions.png and replace this cell with `![Co-mentions graph](co-mentions.png)` to display your graph.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell by a brief commentary, in your own words, of what you see in this graph. What type of graph is it? Which kinds of nodes are high-centrality nodes? Include any aspects that you find relevant from the results of the network analyzer (e.g., number of nodes, edges, connected components, characteristic path lengths, average degrees, etc.) and indicate why those aspects are relevant.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DELIVER (individually)\n",
    "\n",
    "Deliver a zip file containing:\n",
    "\n",
    "* Your code as a Python notebook (a `.ipynb` file).\n",
    "   * Remove all unnecessary elements\n",
    "   * Add comments when needed\n",
    "* Any png files that you inserted in the notebook\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, text, and figures were produced by myself.</font>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
